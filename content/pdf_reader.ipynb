{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ncEinKNz-BT",
        "outputId": "81102017-5f11-4241-f2d8-eca81160c953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.3.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading arxiv-2.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=39a17802ee5347a76d9a72937686f24907806bb5cccbf5238cc9710506664721\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.3.0 feedparser-6.0.12 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arxiv requests tqdm beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "download_engineering_pdfs.py\n",
        "\n",
        "Goal: Download ~150 engineering PDFs (mixed research + lecture notes + textbooks)\n",
        "from arXiv, NPTEL (best-effort), and any manual OpenStax/other URLs provided.\n",
        "\n",
        "Notes:\n",
        "- This script uses a \"fast\" mode (no duplicate checking); it enforces file size < 5 MB.\n",
        "- Place any manual PDF URLs (OpenStax or other sources) line-separated in openstax_urls.txt.\n",
        "- Output folder: data/raw_pdfs/engineering/\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import shutil\n",
        "import requests\n",
        "import arxiv\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "OUT_DIR = \"data/raw_pdfs/engineering\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_COUNT = 150\n",
        "MAX_FILE_SIZE_BYTES = 5 * 1024 * 1024  # 5 MB\n",
        "\n",
        "# Engineering search queries (broad, covers many subdomains)\n",
        "ENGINEERING_QUERIES = [\n",
        "    \"machine learning engineering\",\n",
        "    \"control systems engineering\",\n",
        "    \"thermodynamics engineering\",\n",
        "    \"chemical engineering process\",\n",
        "    \"heat transfer engineering\",\n",
        "    \"transport phenomena engineering\",\n",
        "    \"fluid mechanics engineering\",\n",
        "    \"structural engineering\",\n",
        "    \"power systems electrical engineering\",\n",
        "    \"digital design computer engineering\",\n",
        "    \"aerospace structures\",\n",
        "    \"robotics engineering\",\n",
        "    \"materials science engineering\",\n",
        "    \"signal processing engineering\",\n",
        "    \"embedded systems engineering\",\n",
        "    \"process control chemical engineering\",\n",
        "    \"industrial engineering optimization\",\n",
        "    \"data science engineering\",\n",
        "    \"electronics communication engineering\",\n",
        "    \"civil engineering design\",\n",
        "]\n",
        "\n",
        "# NPTEL base search page (best-effort scraping)\n",
        "NPTEL_SEARCH_BASE = \"https://onlinecourses.nptel.ac.in\"  # base domain used when linking to course pages\n",
        "\n",
        "# Helper utils ---------------------------------------------------------\n",
        "def safe_filename(s: str) -> str:\n",
        "    keep = \"-_.() abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
        "    return \"\".join(c if c in keep else \"_\" for c in s)[:200]\n",
        "\n",
        "def save_response_stream(resp, path):\n",
        "    \"\"\"Save response streaming to file path (write in chunks).\"\"\"\n",
        "    with open(path, \"wb\") as f:\n",
        "        for chunk in resp.iter_content(chunk_size=8192):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def file_too_large(path):\n",
        "    try:\n",
        "        return os.path.getsize(path) > MAX_FILE_SIZE_BYTES\n",
        "    except OSError:\n",
        "        return True\n",
        "\n",
        "def remove_file(path):\n",
        "    try:\n",
        "        os.remove(path)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "# ARXIV downloader ----------------------------------------------------\n",
        "def download_from_arxiv(queries, target_count, out_dir):\n",
        "    \"\"\"Download PDFs from arXiv for given queries until we reach target_count (or run out).\"\"\"\n",
        "    count = 0\n",
        "    # We'll pull in batches per query.\n",
        "    for q in queries:\n",
        "        if count >= target_count:\n",
        "            break\n",
        "        # request more results per query to reach total quota faster\n",
        "        max_results = min(40, target_count - count)  # safety cap per query\n",
        "        search = arxiv.Search(query=q, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
        "        for result in search.results():\n",
        "            if count >= target_count:\n",
        "                break\n",
        "            try:\n",
        "                title = result.title\n",
        "                authors = \"_\".join([a.name.split()[-1] for a in result.authors])[:80]\n",
        "                filename = safe_filename(f\"arxiv_{q[:30]}{authors}{title}.pdf\")\n",
        "                path = os.path.join(out_dir, filename)\n",
        "                # skip if already exists quickly (fast mode may not check duplicates)\n",
        "                if os.path.exists(path):\n",
        "                    continue\n",
        "                # arXiv offers a direct pdf url\n",
        "                pdf_url = result.pdf_url\n",
        "                # try streaming download\n",
        "                try:\n",
        "                    resp = requests.get(pdf_url, stream=True, timeout=30)\n",
        "                    if resp.status_code == 200:\n",
        "                        save_response_stream(resp, path)\n",
        "                        if file_too_large(path):\n",
        "                            remove_file(path)\n",
        "                            # Too large; skip\n",
        "                            continue\n",
        "                        count += 1\n",
        "                    else:\n",
        "                        # fallback: use arxiv result.download_pdf\n",
        "                        try:\n",
        "                            result.download_pdf(filename=path)\n",
        "                            if file_too_large(path):\n",
        "                                remove_file(path)\n",
        "                                continue\n",
        "                            count += 1\n",
        "                        except Exception:\n",
        "                            continue\n",
        "                except Exception:\n",
        "                    # fallback download via arxiv lib\n",
        "                    try:\n",
        "                        result.download_pdf(filename=path)\n",
        "                        if file_too_large(path):\n",
        "                            remove_file(path)\n",
        "                            continue\n",
        "                        count += 1\n",
        "                    except Exception:\n",
        "                        continue\n",
        "            except Exception:\n",
        "                continue\n",
        "    return count\n",
        "\n",
        "# NPTEL downloader (best-effort) -------------------------------------\n",
        "def download_from_nptel(max_courses, out_dir):\n",
        "    \"\"\"\n",
        "    Best-effort NPTEL crawler:\n",
        "    - We attempt to fetch some known NPTEL course pages by iterating through common URL patterns.\n",
        "    - NPTEL structure can change; this is a heuristic.\n",
        "    - If you have specific course list URLs, put them in 'nptel_course_urls.txt' (one per line).\n",
        "    \"\"\"\n",
        "    downloaded = 0\n",
        "    # Try fetching URLs from user-provided file first\n",
        "    course_file = \"nptel_course_urls.txt\"\n",
        "    urls = []\n",
        "    if os.path.exists(course_file):\n",
        "        with open(course_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                u = line.strip()\n",
        "                if u:\n",
        "                    urls.append(u)\n",
        "    else:\n",
        "        # fallback heuristic course listing (popular NPTEL structure uses /courses/)\n",
        "        # We'll try a few common course name seeds combined with branches\n",
        "        seeds = [\n",
        "            \"control-systems\",\n",
        "            \"thermodynamics\",\n",
        "            \"fluid-mechanics\",\n",
        "            \"process-control\",\n",
        "            \"machine-learning\",\n",
        "            \"signal-processing\",\n",
        "            \"power-systems\",\n",
        "            \"design-of-machines\",\n",
        "            \"chemical-process-safety\",\n",
        "            \"engineering-materials\"\n",
        "        ]\n",
        "        branches = [\"iit-kanpur\", \"iit-bombay\", \"iit-delhi\", \"iit-madras\", \"iit-kharagpur\", \"iit-roorkee\"]\n",
        "        for s in seeds:\n",
        "            for b in branches:\n",
        "                # Construct a guess URL (this is heuristic; many won't exist)\n",
        "                urls.append(f\"https://onlinecourses.nptel.ac.in/{b}/flights/{s}.htm\")\n",
        "                urls.append(f\"https://onlinecourses.nptel.ac.in/{b}/{s}.htm\")\n",
        "        urls = list(dict.fromkeys(urls))  # unique\n",
        "\n",
        "    for u in urls:\n",
        "        if downloaded >= max_courses:\n",
        "            break\n",
        "        try:\n",
        "            resp = requests.get(u, timeout=15)\n",
        "            if resp.status_code != 200:\n",
        "                continue\n",
        "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "            # look for links that look like PDFs\n",
        "            for a in soup.find_all(\"a\", href=True):\n",
        "                href = a[\"href\"]\n",
        "                if href.lower().endswith(\".pdf\"):\n",
        "                    pdf_url = href if href.startswith(\"http\") else requests.compat.urljoin(u, href)\n",
        "                    fname = safe_filename(\"nptel_\" + os.path.basename(pdf_url).split(\"?\")[0])\n",
        "                    out_path = os.path.join(out_dir, fname)\n",
        "                    if os.path.exists(out_path):\n",
        "                        continue\n",
        "                    try:\n",
        "                        r = requests.get(pdf_url, stream=True, timeout=30)\n",
        "                        if r.status_code == 200:\n",
        "                            save_response_stream(r, out_path)\n",
        "                            if file_too_large(out_path):\n",
        "                                remove_file(out_path)\n",
        "                                continue\n",
        "                            downloaded += 1\n",
        "                            if downloaded >= max_courses:\n",
        "                                break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "        except Exception:\n",
        "            continue\n",
        "    return downloaded\n",
        "\n",
        "# OPENSTAX / manual URLs loader ---------------------------------------\n",
        "def download_manual_urls(file_with_urls, out_dir, max_count):\n",
        "    \"\"\"\n",
        "    Reads a newline-separated list of PDF URLs (e.g. OpenStax book chapter links or textbook links)\n",
        "    and downloads them until max_count is reached.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_with_urls):\n",
        "        return 0\n",
        "\n",
        "    downloaded = 0\n",
        "    with open(file_with_urls, \"r\") as f:\n",
        "        for line in f:\n",
        "            if downloaded >= max_count:\n",
        "                break\n",
        "            url = line.strip()\n",
        "            if not url:\n",
        "                continue\n",
        "            try:\n",
        "                fname = safe_filename(\"manual_\" + os.path.basename(url).split(\"?\")[0])\n",
        "                out_path = os.path.join(out_dir, fname)\n",
        "                if os.path.exists(out_path):\n",
        "                    continue\n",
        "                r = requests.get(url, stream=True, timeout=30)\n",
        "                if r.status_code == 200:\n",
        "                    save_response_stream(r, out_path)\n",
        "                    if file_too_large(out_path):\n",
        "                        remove_file(out_path)\n",
        "                        continue\n",
        "                    downloaded += 1\n",
        "            except Exception:\n",
        "                continue\n",
        "    return downloaded\n",
        "\n",
        "# MAIN DRIVER ---------------------------------------------------------\n",
        "def main():\n",
        "    print(\"=== Engineering PDF downloader (fast mode, <5MB each) ===\")\n",
        "    total_downloaded = 0\n",
        "\n",
        "    # 1) Try arXiv first (bulk of research PDFs)\n",
        "    remaining = TARGET_COUNT - total_downloaded\n",
        "    if remaining > 0:\n",
        "        print(f\"\\n-> Downloading from arXiv (target: {remaining}) ...\")\n",
        "        downloaded = download_from_arxiv(ENGINEERING_QUERIES, remaining, OUT_DIR)\n",
        "        total_downloaded += downloaded\n",
        "        print(f\"arXiv downloaded: {downloaded} (total {total_downloaded})\")\n",
        "\n",
        "    # 2) Try NPTEL lecture notes (best-effort)\n",
        "    remaining = TARGET_COUNT - total_downloaded\n",
        "    if remaining > 0:\n",
        "        # limit number of NPTEL downloads to a portion (e.g., up to 40)\n",
        "        nptel_target = min(40, remaining)\n",
        "        print(f\"\\n-> Attempting to fetch lecture PDFs from NPTEL (target: {nptel_target}) ...\")\n",
        "        nptel_downloaded = download_from_nptel(nptel_target, OUT_DIR)\n",
        "        total_downloaded += nptel_downloaded\n",
        "        print(f\"NPTEL downloaded: {nptel_downloaded} (total {total_downloaded})\")\n",
        "\n",
        "    # 3) Manual OpenStax / textbook / misc URLs (put them in openstax_urls.txt)\n",
        "    remaining = TARGET_COUNT - total_downloaded\n",
        "    if remaining > 0:\n",
        "        print(f\"\\n-> Downloading manual URLs from openstax_urls.txt (target: {remaining}) ...\")\n",
        "        manual_downloaded = download_manual_urls(\"openstax_urls.txt\", OUT_DIR, remaining)\n",
        "        total_downloaded += manual_downloaded\n",
        "        print(f\"Manual urls downloaded: {manual_downloaded} (total {total_downloaded})\")\n",
        "\n",
        "    print(\"\\n=== Summary ===\")\n",
        "    print(f\"Total PDFs downloaded: {total_downloaded}/{TARGET_COUNT}\")\n",
        "    print(f\"Saved to folder: {OUT_DIR}\")\n",
        "    print(\"Note: files > 5MB are removed automatically. If you want more PDFs, you can re-run the script or add manual URLs.\")\n",
        "    print(\"Done.\")\n"
      ],
      "metadata": {
        "id": "EoUxHLAw0MGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F18BCdi20Wg4",
        "outputId": "07817f92-c93a-4751-9c13-dda3025de8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Engineering PDF downloader (fast mode, <5MB each) ===\n",
            "\n",
            "-> Downloading from arXiv (target: 150) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138557414.py:92: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arXiv downloaded: 150 (total 150)\n",
            "\n",
            "=== Summary ===\n",
            "Total PDFs downloaded: 150/150\n",
            "Saved to folder: data/raw_pdfs/engineering\n",
            "Note: files > 5MB are removed automatically. If you want more PDFs, you can re-run the script or add manual URLs.\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF nltk tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9gNQ9UX0Xnt",
        "outputId": "410a4fdb-91d4-4d76-d8f6-6b85ca2c191c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWb8rxLH1v34",
        "outputId": "019be0fe-681b-4825-e45e-39412a0cabfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "PDF_DIR = \"/content/data/raw_pdfs/engineering\"\n",
        "CHUNK_DIR = \"/content/data/chunks\"\n",
        "os.makedirs(CHUNK_DIR, exist_ok=True)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts plain text from a PDF.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page in doc:\n",
        "                text += page.get_text(\"text\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö† Error reading {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def create_chunks(text, max_words=180):\n",
        "    \"\"\"Splits long text into readable chunks.\"\"\"\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks, current_chunk, count = [], \"\", 0\n",
        "\n",
        "    for sent in sentences:\n",
        "        words = sent.split()\n",
        "        if count + len(words) <= max_words:\n",
        "            current_chunk += \" \" + sent\n",
        "            count += len(words)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sent\n",
        "            count = len(words)\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# ---- Process all PDFs ----\n",
        "chunk_count = 0\n",
        "for pdf_file in tqdm(os.listdir(PDF_DIR)[::20], desc=\"üìö Processing PDFs\"):\n",
        "    if pdf_file.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(PDF_DIR, pdf_file)\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        if not text.strip():\n",
        "            continue\n",
        "        chunks = create_chunks(text)\n",
        "\n",
        "        # Save chunks as text files\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            chunk_filename = f\"{os.path.splitext(pdf_file)[0]}chunk{i}.txt\"\n",
        "            with open(os.path.join(CHUNK_DIR, chunk_filename), \"w\") as f:\n",
        "                f.write(chunk)\n",
        "            chunk_count += 1\n",
        "\n",
        "print(f\"\\n‚úÖ Done! Total chunks created: {chunk_count}\")\n",
        "print(f\"üìÇ Saved inside: {CHUNK_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VSjpEBU1y4h",
        "outputId": "bfa55b60-6b95-4a73-9950-fc9d3b613c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "üìö Processing PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Done! Total chunks created: 693\n",
            "üìÇ Saved inside: /content/data/chunks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.genai as genai  # <-- Keep this line\n",
        "\n",
        "# --- Verification Step ---\n",
        "api_key_status = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "if api_key_status:\n",
        "    print(\"‚úÖ GEMINI_API_KEY is loaded in this session.\")\n",
        "else:\n",
        "    print(\"‚ùå GEMINI_API_KEY is NOT loaded in this session.\")\n",
        "    # Prompt user to input the key securely\n",
        "    from getpass import getpass\n",
        "    api_key = getpass(\"Enter your GEMINI_API_KEY: \")\n",
        "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
        "    print(\"üîë GEMINI_API_KEY has been set for this session.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N48-yAMw12LQ",
        "outputId": "92e6c1e7-0b30-4c61-a33c-81f6732a0891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå GEMINI_API_KEY is NOT loaded in this session.\n",
            "Enter your GEMINI_API_KEY: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "üîë GEMINI_API_KEY has been set for this session.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OhipT142z4P",
        "outputId": "d8961208-3c07-495e-95f6-4a99d5df55f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines) (25.4.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/data/dataset/\"\n",
        "os.makedirs(DATASET_PATH, exist_ok=True)"
      ],
      "metadata": {
        "id": "AxU0DbKl23Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import jsonlines\n",
        "from tqdm import tqdm\n",
        "import google.generativeai as genai\n",
        "\n",
        "CHUNK_DIR = \"/content/data/chunks\"\n",
        "DATASET_PATH = \"/content/data/dataset/train.jsonl\"\n",
        "MAX_SAMPLES = 500  # stops after creating 500 samples\n",
        "\n",
        "def generate_summary(chunk):\n",
        "    prompt = f\"\"\"\n",
        "    Summarize this in 10 academic-style sentences:\n",
        "    {chunk}\n",
        "    \"\"\"\n",
        "    response = genai.GenerativeModel(\"gemini-2.5-flash\").generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "def generate_questions(chunk):\n",
        "    prompt = f\"\"\"\n",
        "    Create 4 exam-style questions and answers from this:\n",
        "    {chunk}\n",
        "\n",
        "    Use this format strictly:\n",
        "    Q1:\n",
        "    A1:\n",
        "    Q2:\n",
        "    A2:\n",
        "    Q3:\n",
        "    A3:\n",
        "    Q4:\n",
        "    A4:\n",
        "    \"\"\"\n",
        "    response = genai.GenerativeModel(\"gemini-2.5-flash\").generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "output_count = 0\n",
        "with jsonlines.open(DATASET_PATH, mode='w') as writer:\n",
        "    for chunk_file in tqdm(os.listdir(CHUNK_DIR), desc=\"Generating Dataset\"):\n",
        "        if output_count >= MAX_SAMPLES:\n",
        "            break\n",
        "\n",
        "        with open(os.path.join(CHUNK_DIR, chunk_file), 'r') as f:\n",
        "            chunk = f.read()\n",
        "\n",
        "        try:\n",
        "            summary = generate_summary(chunk)\n",
        "            qa = generate_questions(chunk)\n",
        "\n",
        "            writer.write({\n",
        "                \"input\": f\"<TASK_SUMMARY>\\nContext:\\n{chunk}\",\n",
        "                \"output\": summary\n",
        "            })\n",
        "            writer.write({\n",
        "                \"input\": f\"<TASK_QUESTIONS>\\nContext:\\n{chunk}\",\n",
        "                \"output\": qa\n",
        "            })\n",
        "\n",
        "            output_count += 2  # 1 summary + 1 Q&A\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† Skipped {chunk_file}: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset created: {DATASET_PATH}\")\n",
        "print(f\"üì¶ Total dataset entries: {output_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qOgl6X1H2TfL",
        "outputId": "5de68166-15ce-4f0d-e86c-549dcff476fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Dataset:  13%|‚ñà‚ñé        | 93/693 [36:55<3:21:54, 20.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk137.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 33.524303552s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 33\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  14%|‚ñà‚ñé        | 94/693 [36:56<2:21:47, 14.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk258.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 33.309157942s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 33\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  14%|‚ñà‚ñé        | 95/693 [37:03<2:01:21, 12.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk27.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 25.852520062s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 25\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  14%|‚ñà‚ñç        | 96/693 [37:13<1:54:44, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk195.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 15.823731689s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 15\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Dataset:  14%|‚ñà‚ñç        | 98/693 [37:31<1:33:25,  9.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk68.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 57.951341878s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  14%|‚ñà‚ñç        | 99/693 [37:31<1:05:54,  6.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk197.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 57.745622773s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  14%|‚ñà‚ñç        | 100/693 [37:31<46:42,  4.73s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_machine learning engineeringShafiq_Mashkoor_Mayr-Dorn_EgyedMachine Learning for Software Engineering_ A Systematic Mappingchunk88.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 57.531911014s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñç        | 101/693 [37:32<33:18,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_control systems engineeringDasControl System Design Using Finite Laplace Transform Theorychunk23.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 57.315559759s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñç        | 102/693 [37:32<23:57,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk187.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 57.084445946s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñç        | 103/693 [37:41<42:57,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_machine learning engineeringShafiq_Mashkoor_Mayr-Dorn_EgyedMachine Learning for Software Engineering_ A Systematic Mappingchunk17.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 48.19166123s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 48\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñå        | 104/693 [37:41<30:41,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_machine learning engineeringShafiq_Mashkoor_Mayr-Dorn_EgyedMachine Learning for Software Engineering_ A Systematic Mappingchunk66.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 47.974944385s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 47\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñå        | 105/693 [37:41<22:04,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk71.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 47.740046714s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 47\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñå        | 106/693 [37:41<16:02,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_chemical engineering processWang_WuTowards Foundation Model for Chemical Reactor Modeling_ Meta-Learning with Physics-Informed Adaptationchunk64.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 47.534461891s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 47\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  15%|‚ñà‚ñå        | 107/693 [37:42<11:50,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_machine learning engineeringThebelt_Wiebe_Kronqvist_Tsay_MisenerMaximizing information from chemical engineering data sets_ Applications to machine learningchunk58.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 47.321167113s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 47\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  16%|‚ñà‚ñå        | 108/693 [37:42<08:56,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk126.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 47.103616907s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 47\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  16%|‚ñà‚ñå        | 109/693 [37:42<06:53,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_machine learning engineeringShafiq_Mashkoor_Mayr-Dorn_EgyedMachine Learning for Software Engineering_ A Systematic Mappingchunk60.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 46.881390048s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  16%|‚ñà‚ñå        | 110/693 [37:42<05:27,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_machine learning engineeringShafiq_Mashkoor_Mayr-Dorn_EgyedMachine Learning for Software Engineering_ A Systematic Mappingchunk5.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 46.657582781s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  16%|‚ñà‚ñå        | 111/693 [37:43<04:28,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk88.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 46.435797954s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  16%|‚ñà‚ñå        | 112/693 [37:43<03:46,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† Skipped arxiv_thermodynamics engineeringElouardThermodynamics of Quantum Open Systems_ Applications in Quantum Optics and Optomechanicschunk40.txt: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 46.204073277s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 46\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Dataset:  16%|‚ñà‚ñå        | 112/693 [37:43<3:15:41, 20.21s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-73644529.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-73644529.py\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(chunk)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gemini-2.5-flash\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     ) -> Any:\n\u001b[0;32m--> 276\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    312\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    315\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     ) -> Tuple[Any, grpc.Call]:\n\u001b[0;32m-> 1177\u001b[0;31m         state, call = self._blocking(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             )\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/tag.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/operation.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_cls, key, value)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/data/chunks"
      ],
      "metadata": {
        "id": "qLenI3lM3kfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7doXe2H9bKN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}